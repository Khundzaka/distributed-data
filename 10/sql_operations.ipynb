{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b98ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/22 18:06:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3b0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_schema = StructType([\n",
    "    StructField('Store', IntegerType()),\n",
    "    StructField('Type', StringType()),\n",
    "    StructField('Size', IntegerType())\n",
    "])\n",
    "df_stores = spark.read.format('csv').option(\"header\", True).schema(stores_schema).load('./input/stores.csv')\n",
    "df_stores.createOrReplaceTempView('stores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005becf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = spark.read.format('csv').option(\"header\", True).load('./input/features.csv')\n",
    "df_features.createOrReplaceTempView('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31922c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|   Store|      int|   null|\n",
      "|    Type|   string|   null|\n",
      "|    Size|      int|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Describe stores\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fda9ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|store|  size|\n",
      "+-----+------+\n",
      "|    1|151315|\n",
      "|    2|202307|\n",
      "|    3| 37392|\n",
      "|    4|205863|\n",
      "|    5| 34875|\n",
      "+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select store, size from stores\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d527451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|Store|Type|  Size|\n",
      "+-----+----+------+\n",
      "|    2|   A|202307|\n",
      "|    4|   A|205863|\n",
      "|    6|   A|202505|\n",
      "|   11|   A|207499|\n",
      "|   13|   A|219622|\n",
      "+-----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select * from stores where type = 'A' AND size > 200000\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc025cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------------+--------+\n",
      "|type|sum(size)|         avg(size)|count(1)|\n",
      "+----+---------+------------------+--------+\n",
      "|   B|  1720242|101190.70588235294|      17|\n",
      "|   C|   243250|40541.666666666664|       6|\n",
      "|   A|  3899450|177247.72727272726|      22|\n",
      "+----+---------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select type, SUM(size), avg(size), count(1) from stores Group by type\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7736b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+--------------------+\n",
      "|store|type|  size|                 sum|\n",
      "+-----+----+------+--------------------+\n",
      "|    1|   A|151315|            [151315]|\n",
      "|    2|   A|202307|    [151315, 202307]|\n",
      "|    4|   A|205863|[151315, 202307, ...|\n",
      "|    6|   A|202505|[151315, 202307, ...|\n",
      "|    8|   A|155078|[151315, 202307, ...|\n",
      "|   11|   A|207499|[151315, 202307, ...|\n",
      "|   13|   A|219622|[151315, 202307, ...|\n",
      "|   14|   A|200898|[151315, 202307, ...|\n",
      "|   19|   A|203819|[151315, 202307, ...|\n",
      "|   20|   A|203742|[151315, 202307, ...|\n",
      "|   24|   A|203819|[151315, 202307, ...|\n",
      "|   26|   A|152513|[151315, 202307, ...|\n",
      "|   27|   A|204184|[151315, 202307, ...|\n",
      "|   28|   A|206302|[151315, 202307, ...|\n",
      "|   31|   A|203750|[151315, 202307, ...|\n",
      "|   32|   A|203007|[151315, 202307, ...|\n",
      "|   33|   A| 39690|[151315, 202307, ...|\n",
      "|   34|   A|158114|[151315, 202307, ...|\n",
      "|   36|   A| 39910|[151315, 202307, ...|\n",
      "|   39|   A|184109|[151315, 202307, ...|\n",
      "|   40|   A|155083|[151315, 202307, ...|\n",
      "|   41|   A|196321|[151315, 202307, ...|\n",
      "|    3|   B| 37392|             [37392]|\n",
      "|    5|   B| 34875|      [37392, 34875]|\n",
      "|    7|   B| 70713|[37392, 34875, 70...|\n",
      "|    9|   B|125833|[37392, 34875, 70...|\n",
      "|   10|   B|126512|[37392, 34875, 70...|\n",
      "|   12|   B|112238|[37392, 34875, 70...|\n",
      "|   15|   B|123737|[37392, 34875, 70...|\n",
      "|   16|   B| 57197|[37392, 34875, 70...|\n",
      "|   17|   B| 93188|[37392, 34875, 70...|\n",
      "|   18|   B|120653|[37392, 34875, 70...|\n",
      "|   21|   B|140167|[37392, 34875, 70...|\n",
      "|   22|   B|119557|[37392, 34875, 70...|\n",
      "|   23|   B|114533|[37392, 34875, 70...|\n",
      "|   25|   B|128107|[37392, 34875, 70...|\n",
      "|   29|   B| 93638|[37392, 34875, 70...|\n",
      "|   35|   B|103681|[37392, 34875, 70...|\n",
      "|   45|   B|118221|[37392, 34875, 70...|\n",
      "|   30|   C| 42988|             [42988]|\n",
      "|   37|   C| 39910|      [42988, 39910]|\n",
      "|   38|   C| 39690|[42988, 39910, 39...|\n",
      "|   42|   C| 39690|[42988, 39910, 39...|\n",
      "|   43|   C| 41062|[42988, 39910, 39...|\n",
      "|   44|   C| 39910|[42988, 39910, 39...|\n",
      "+-----+----+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select store, type, size, collect_list(size) over (PARTITION by type order by store) as sum from stores\")\n",
    "df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4f133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------------+\n",
      "|store|first(type)|             price|\n",
      "+-----+-----------+------------------+\n",
      "|    1|          A| 3.259241758241762|\n",
      "|    2|          A| 3.259241758241762|\n",
      "|    3|          B| 3.259241758241762|\n",
      "|    4|          A|3.2548846153846154|\n",
      "|    5|          B| 3.259241758241762|\n",
      "|    6|          A| 3.259241758241762|\n",
      "|    7|          B|3.2944010989010986|\n",
      "|    8|          A| 3.259241758241762|\n",
      "|    9|          B| 3.259241758241762|\n",
      "|   10|          B|3.6156483516483515|\n",
      "|   11|          A| 3.259241758241762|\n",
      "|   12|          B| 3.643653846153846|\n",
      "|   13|          A| 3.328763736263739|\n",
      "|   14|          A|3.4764120879120886|\n",
      "|   15|          B| 3.643357142857143|\n",
      "|   16|          B|3.2944010989010986|\n",
      "|   17|          B| 3.328763736263739|\n",
      "|   18|          B|3.4978736263736248|\n",
      "|   19|          A| 3.643357142857143|\n",
      "|   20|          A|3.4764120879120886|\n",
      "|   21|          B| 3.259241758241762|\n",
      "|   22|          B|3.4978736263736248|\n",
      "|   23|          B|3.4978736263736248|\n",
      "|   24|          A| 3.643357142857143|\n",
      "|   25|          B|3.4764120879120886|\n",
      "|   26|          A|3.4978736263736248|\n",
      "|   27|          A| 3.643357142857143|\n",
      "|   28|          A| 3.643653846153846|\n",
      "|   29|          B|3.4978736263736248|\n",
      "|   30|          C| 3.259241758241762|\n",
      "|   31|          A| 3.259241758241762|\n",
      "|   32|          A|3.2944010989010986|\n",
      "|   33|          A|3.6156483516483515|\n",
      "|   34|          A|3.2548846153846154|\n",
      "|   35|          B|3.4764120879120886|\n",
      "|   36|          A|3.2459450549450533|\n",
      "|   37|          C| 3.259241758241762|\n",
      "|   38|          C| 3.643653846153846|\n",
      "|   39|          A| 3.259241758241762|\n",
      "|   40|          A|3.4978736263736248|\n",
      "|   41|          A|3.2944010989010986|\n",
      "|   42|          C|3.6156483516483515|\n",
      "|   43|          C| 3.259241758241762|\n",
      "|   44|          C| 3.328763736263739|\n",
      "|   45|          B|3.4764120879120886|\n",
      "+-----+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select stores.store as store, first(type), avg(features.fuel_price) as price from stores left join features on stores.store = features.store group by stores.store\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373f6848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------------------+\n",
      "|store|first(type)|               price|\n",
      "+-----+-----------+--------------------+\n",
      "|   31|          A|[3.62, 3.556, 3.4...|\n",
      "|   34|          A|[3.58, 3.518, 3.3...|\n",
      "|   28|          A|[3.865, 3.823, 3....|\n",
      "|   26|          A|[3.879, 3.803, 3....|\n",
      "|   27|          A|[3.951, 3.913, 3....|\n",
      "+-----+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"Select stores.store as store, first(type), collect_list(features.fuel_price) as price from stores left join features on stores.store = features.store group by stores.store\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f77a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
